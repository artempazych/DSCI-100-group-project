{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a959c5be-d17e-40ce-aed8-225ffaccc4ad",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "**Answering the Predictive Question:**\n",
    "\n",
    "The question that we are trying to answer by using our classifier is: **“Is a firm at risk of fraud?”**. To address this question, we have made two classifiers that can predict risk based on *(PARA_A, PARA_B, and Money_Value)* and *(PARA_A and PARA_B)* respectively. \n",
    "\n",
    "**Summary of Results:** \n",
    "\n",
    "Based on the visualizations, we observe that there is no significant relationship between the discrepancy found in planned expenditure *(PARA_A)* and the discrepancy found in unplanned expenditure *(PARA_B)* because they form separate clusters (Figure 1).\n",
    "\n",
    "**Model 1:** In this model, we used three predictor variables *(PARA_A, PARA_B, and Money_Value)*. After performing a five-fold cross-validation, we found out that the best possible value of k for our model is 4 as the accuracy remained almost the same even if we increase or decrease the value of k by one (Figure 3). The model predicted a total of 195 labels, of which 174 were correct. We can see that only 5 of 73 not-risk companies were wrongly classified as risky, and 17 companies out of 122 risk companies were misclassified as not risky (Table 4). Overall, we were able to achieve an accuracy of 88.7% from this model. \n",
    "\n",
    "**Model 2:** In this model, we used two predictor variables *(PARA_A and PARA_B)*. After performing five-fold cross-validation, we found out that the best possible value of k for this model is 5 because the accuracy of the model almost remained the same after that (Figure 4). We can infer that only 1 of 73, not risk companies were incorrectly classified as risky and 22 of 122 risk companies were incorrectly classified as not risky (Table 5). This model has an accuracy of 88.2%. This model does a good job of predicting the risk of a firm only on the basis of 2 parameters. \n",
    "\n",
    "As the results show, both models have almost the same accuracy. Both models did a good job of predicting the risk. However, model 1 misclassifies more risky companies as not risky. Therefore, we would prefer model 1 over model 2 to predict the risk of a firm. \n",
    "\n",
    "\n",
    "**Impact of Results:** \n",
    "\n",
    "There have been many instances where a firm forges its annual reports and other statistics to attract investment from clients [1,2,3]. Our classification model can be used to predict whether a firm is risky or not. It could reduce the chances of investors losing their money. Further, it can help the client to choose the firm that suits their risk appetite. \n",
    "\n",
    "Knn classification is very advantageous because it can be implemented to make predictions even though the relationship between the predictors and target variable is not linear, which is most likely the case with firm data. Moreover, it is not affected by the presence of noisy data. However, the value of k (number of nearest neighbors) has to be determined using cross-validation; this process requires high computation power if a large dataset is being analyzed.\n",
    "\n",
    "\n",
    "\n",
    "**Further Projects Based on Results:** \n",
    "\n",
    "In our project, we analyzed only a small piece of data because we were limited by the server and computational power; our next step, hopefully, would be to improve the computational power, either through a hardware upgrade or through BigQuery to process larger datasets. This would be a huge improvement to the accuracy of the model and have a larger impact. \n",
    "\n",
    "Our project leads to the following future questions: \n",
    "1. Besides *PARA_A, PARA_B, and Money_Value,*  what other factors can be used to predict if a firm is at risk of fraud? \n",
    "\n",
    "2. How can we make our model more versatile (i.e. usable in other larger datasets)? \n",
    "\n",
    "\n",
    "**References:** \n",
    "\n",
    "1. Hooda, N., Bawa, S., & Rana, P. S. (2018). Fraudulent firm classification: a case study of an external audit. Applied Artificial Intelligence, 32(1), 48-64.\n",
    "\n",
    "2. Tysiac, K. (2015). Data analytics helps auditors gain deep insight. Journal of Accountancy, 219(4), 52.\n",
    "\n",
    "3. Zhao, Z., & Bai, T. (2022). Financial Fraud Detection and Prediction in Listed Companies Using SMOTE and Machine Learning Algorithms. Entropy, 24(8), 1157.\n",
    "\n",
    "4. Hooda, N. (2018, July 14). Audit Data Data Set. Retrieved November 22, 2022, from https://archive.ics.uci.edu/ml/datasets/Audit+Data.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
